{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils \n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.optimize import minimize, LinearConstraint\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('data_new.csv', delimiter=',', dtype=str)\n",
    "data = np.delete(data, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "# turn each game into entry in this array\n",
    "\n",
    "def remove_blank(l):\n",
    "    return list(filter(lambda a: a != '', l))\n",
    "\n",
    "def replace_letters(l):\n",
    "   return [[1,0] if x=='c' else [0, 1] for x in l]\n",
    "\n",
    "for i in range(0, data.shape[0], 2):\n",
    "    p1 = data[i]\n",
    "    p2 = data[i+1]\n",
    "\n",
    "    game = int(p1[0])\n",
    "    player1 = p1[2]\n",
    "    player2 = p2[2]\n",
    "    p1_actions = np.array(replace_letters(remove_blank(p1[3:]))).T\n",
    "    p2_actions =  np.array(replace_letters(remove_blank(p2[3:]))).T\n",
    "   \n",
    "    actions =  [p1_actions, p2_actions]\n",
    "\n",
    "    new_data.append([game, player1, player2, actions])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_data)\n",
    "df.columns = ['Game', 'Player_1', 'Player_2', 'Actions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Player_1</th>\n",
       "      <th>Player_2</th>\n",
       "      <th>Actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Faisal</td>\n",
       "      <td>Bharathvaj</td>\n",
       "      <td>[[[0, 1, 1, 1, 0], [1, 0, 0, 0, 1]], [[1, 0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yuan</td>\n",
       "      <td>Dagmar</td>\n",
       "      <td>[[[1, 0, 0], [0, 1, 1]], [[1, 1, 0], [0, 0, 1]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ehsan</td>\n",
       "      <td>Mohammend</td>\n",
       "      <td>[[[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tao</td>\n",
       "      <td>Rohini</td>\n",
       "      <td>[[[0, 1, 0, 1, 1], [1, 0, 1, 0, 0]], [[1, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Anita</td>\n",
       "      <td>Greg</td>\n",
       "      <td>[[[1, 1, 0, 1, 1, 1, 0], [0, 0, 1, 0, 0, 0, 1]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Game Player_1    Player_2  \\\n",
       "0     0   Faisal  Bharathvaj   \n",
       "1     1    yuan       Dagmar   \n",
       "2     2    Ehsan   Mohammend   \n",
       "3     3      Tao      Rohini   \n",
       "4     4    Anita        Greg   \n",
       "\n",
       "                                             Actions  \n",
       "0  [[[0, 1, 1, 1, 0], [1, 0, 0, 0, 1]], [[1, 0, 1...  \n",
       "1   [[[1, 0, 0], [0, 1, 1]], [[1, 1, 0], [0, 0, 1]]]  \n",
       "2  [[[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0], [0, 0,...  \n",
       "3  [[[0, 1, 0, 1, 1], [1, 0, 1, 0, 0]], [[1, 0, 0...  \n",
       "4  [[[1, 1, 0, 1, 1, 1, 0], [0, 0, 1, 0, 0, 0, 1]...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40151515 0.59848485]\n",
      "[0.48484848 0.51515152]\n"
     ]
    }
   ],
   "source": [
    "s1 = np.zeros(2)\n",
    "s2 = np.zeros(2)\n",
    "\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    actions = row.Actions\n",
    "    \n",
    "    for round in range( actions[0].shape[1]): # iterate over length of each game \n",
    "        s1 += actions[0][:, round]\n",
    "        s2 += actions[1][:, round]\n",
    "        \n",
    "    # frequency of each\n",
    "print(s1/np.sum(s1))\n",
    "print(s2/np.sum(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_traj(a, s):\n",
    "    '''\n",
    "    Returns the probability of a sequence of actions\n",
    "    a being sampled from strategy s.\n",
    "\n",
    "    Paramters:\n",
    "        a : (np.Array) 2 x n array of actions chosen\n",
    "        s : (np.Array) 2 x n array of strategies \n",
    "    '''\n",
    "\n",
    "    assert a.shape == s.shape\n",
    "    L = a.shape[1]\n",
    "    prod = 1\n",
    "    for l in range(L):\n",
    "        idx = np.where(a[:, l])\n",
    "        prod *= s[:, l][idx][0]\n",
    "\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(df.Actions)\n",
    "traj = data[0][0][:, 0:3]\n",
    "s = np.array([[0.9, 0.1], [0.6, 0.4], [.3, .7] ]).T\n",
    "assert p_traj(traj, s) == 0.018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_outcomes(s):\n",
    "    '''\n",
    "    returns a probability distribution over outcomes\n",
    "    '''\n",
    "    p = s[0]\n",
    "    for s_i in s[1:]:\n",
    "        p =  np.multiply.outer(p, s_i)\n",
    "    return p\n",
    "\n",
    "def expected_utility(s, payoffs):\n",
    "    '''\n",
    "    Gets the expected utilitiy for a player under strategy profile s\n",
    "    \n",
    "    Parameters\n",
    "        s : (list) list where S[i] gives the probability of player i playing each action\n",
    "        payoffs: (np.array) payoffs for i\n",
    "    Returns\n",
    "        eu : (float) expected utility for i\n",
    "    '''\n",
    "    p = p_outcomes(s)\n",
    "    return np.sum(np.multiply(p, payoffs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-182.99085566782566"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ll_uniform( dataset):\n",
    "    ll = 0\n",
    "    for play in dataset: \n",
    "        for player in range(2):\n",
    "            traj = play[player]\n",
    "            s = np.ones_like(traj) / np.ones(traj.shape[1])*2\n",
    "            ll += np.log(p_traj(traj, s))\n",
    "    return -ll\n",
    "\n",
    "ll_uniform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spite_Model:\n",
    "    def __init__(self, h):\n",
    "        self.h = h\n",
    "        self.payoffs = np.zeros([2, 2, 2])\n",
    "        self.payoffs[0, :, :] = np.array([[0, -1],\n",
    "                                          [1, -2]])\n",
    "        \n",
    "        self.payoffs[1, :, :] = np.array([[0, 1],\n",
    "                                         [-1, -2]])\n",
    "        self.alphas = None\n",
    "    \n",
    "\n",
    "    def log_likelihood_independent(self, params, dataset):\n",
    "        '''\n",
    "        Given the dataset and the fitted model, returns the log likelihood. This assumes a players level may change as the game goes on\n",
    "\n",
    "        NOTE: assumes each player has a fixed level\n",
    "        \n",
    "        Parameters:\n",
    "            params : np.array of alpha_ks, the freq of that level in population and lambda_ for QBR\n",
    "            dataset : list of plays, each play is an np array\n",
    "        Returns:\n",
    "            ll : loglikelihood of dataset\n",
    "\n",
    "        '''\n",
    "        \n",
    "        alphas = params[0:-2]\n",
    "        lambda_ = params[-2] \n",
    "        kappa  = params[-1] \n",
    "\n",
    "        ll = 0\n",
    "        for play in dataset: \n",
    "            for player in range(2):\n",
    "                traj = play[player]\n",
    "                other_traj  = play[1-player] # trajectory of other player\n",
    "                \n",
    "                pred_s = self.predict_traj(traj, other_traj, self.K, lambda_, kappa, overall=True, alphas=alphas)  \n",
    "               \n",
    "                L = traj.shape[1] #length of trajectory\n",
    "                for l in range(L):\n",
    "                    idx = np.where(traj[:, l])\n",
    "                    ll += np.log(pred_s[:, l][idx][0])\n",
    "\n",
    "        return -ll # since we are minimizing the negative log likelihood\n",
    "\n",
    "\n",
    "    def log_likelihood(self, params, dataset):\n",
    "        '''\n",
    "        Given the dataset and the fitted model, returns the log likelihood.\n",
    "\n",
    "        NOTE: assumes each player has a fixed level\n",
    "        \n",
    "        Parameters:\n",
    "            params : np.array of alpha_ks, the freq of that level in population and lambda_ for QBR\n",
    "            dataset : list of plays, each play is an np array\n",
    "        Returns:\n",
    "            ll : loglikelihood of dataset\n",
    "\n",
    "        '''\n",
    "        spite_coeff = params[0] # weighting between spiteful strategy and QBR\n",
    "        lambda_ = params[1]\n",
    "       \n",
    "        ll = 0\n",
    "        for play in dataset: \n",
    "            for player in range(2):\n",
    "                traj = play[player]\n",
    "                other_traj  = play[1-player] # trajectory of other player\n",
    "                \n",
    "                pred_s = self.predict_traj(traj, other_traj, spite_coeff, lambda_)  \n",
    "               \n",
    "                L = traj.shape[1] #length of trajectory\n",
    "                for l in range(L):\n",
    "                    idx = np.where(traj[:, l])\n",
    "                    ll += np.log(pred_s[:, l][idx][0]+0.00001)\n",
    "\n",
    "\n",
    "        return -ll # since we are minimizing the negative log likelihood\n",
    "\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        num_params = 2\n",
    "\n",
    "        params = np.zeros(num_params) # +2 since level 0 and the lambda parameter, kappa parameter\n",
    "\n",
    "\n",
    "\n",
    "        #const_arr = np.ones(num_params)\n",
    "        #constraint = LinearConstraint(const_arr, lb=1, ub=1)\n",
    "        bnds = [(0, 1) , (0, 10)]\n",
    "        #bnds = [(0, 10) for x in range(1)]\n",
    "    \n",
    "\n",
    "        result = minimize(\n",
    "            self.log_likelihood ,\n",
    "            params, \n",
    "            args=(dataset),\n",
    "            bounds=bnds) \n",
    "\n",
    "        assert result.status == 0 # make sure the optimization was successful\n",
    "        return result\n",
    "\n",
    "\n",
    "    def predict_traj(self, traj, other_traj, spite_coeff, lambda_):\n",
    "        '''\n",
    "        Returns straetgy predictions against other player\n",
    "        \n",
    "        '''\n",
    "\n",
    "        play_len = traj.shape[1]\n",
    "        pred_i = np.zeros((2, play_len))\n",
    "\n",
    "        for l in range(play_len):\n",
    "            if l ==0:\n",
    "                pred_i[:, l] = np.ones(2)/2\n",
    "               \n",
    "            else:\n",
    "                if np.array_equal(other_traj[:, l-1], np.array([0, 1])):\n",
    "                    pred_i[:, l] = (1-spite_coeff) * self.compute_BR(other_traj[:, l-1], lambda_) + spite_coeff * np.array([0,1])\n",
    "                else:\n",
    "                    # print(pred_i.shape)\n",
    "                    # print(other_traj.shape)\n",
    "                    pred_i[:, l] = self.compute_BR(other_traj[:, l-1], lambda_)\n",
    "\n",
    "        return pred_i   \n",
    "\n",
    "\n",
    "    def compute_BR(self,  s_other, lambda_):\n",
    "        '''\n",
    "        Computes a best response\n",
    "\n",
    "        Parameters:\n",
    "            s_other : (np.Array) strategy of other player\n",
    "\n",
    "        NOTE: this ONLY works with symetric payoffs and 2 actions\n",
    "        '''\n",
    "    \n",
    "        #get EU of action 0\n",
    "        s = [np.array([1, 0]), s_other]\n",
    "        eu_0 = expected_utility(s, self.payoffs[0])\n",
    "\n",
    "        # get EU of action 1\n",
    "        s = [np.array([0, 1]), s_other]\n",
    "        eu_1 = expected_utility(s, self.payoffs[0])\n",
    "\n",
    "        # return action with greater EU\n",
    "        return softmax(np.array([eu_0, eu_1])*lambda_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bounded_Memory_Map:\n",
    "    def __init__(self, h):\n",
    "        self.h = h\n",
    "        self.payoffs = np.zeros([2, 2, 2])\n",
    "        self.payoffs[0, :, :] = np.array([[0, -1],\n",
    "                                 [1, -2]])\n",
    "        \n",
    "        self.payoffs[1, :, :] = np.array([[0, 1],\n",
    "                                        [-1, -2]])\n",
    "        self.alphas = None\n",
    "\n",
    "    def log_likelihood(self, params, dataset):\n",
    "        '''\n",
    "        Given the dataset and the fitted model, returns the log likelihood.\n",
    "\n",
    "        NOTE: assumes each player has a fixed level\n",
    "        \n",
    "        Parameters:\n",
    "            params : np.array of alpha_ks, the freq of that level in population and lambda_ for QBR\n",
    "            dataset : list of plays, each play is an np array\n",
    "        Returns:\n",
    "            ll : loglikelihood of dataset\n",
    "\n",
    "        '''       \n",
    "        num_features = len(self.get_features(0, 1))\n",
    "        M = params[:-1].reshape((num_features, num_features))\n",
    "        lambda_ = params[-1]\n",
    "\n",
    "\n",
    "        ll = 0\n",
    "        for play in dataset: \n",
    "            for player in range(2):\n",
    "                traj = play[player]\n",
    "                other_traj  = play[1-player] # trajectory of other player\n",
    "                \n",
    "                pred_s = self.predict_traj(traj, other_traj, M, player,  lambda_)  \n",
    "               \n",
    "                L = traj.shape[1] #length of trajectory\n",
    "                for l in range(L):\n",
    "                    idx = np.where(traj[:, l])\n",
    "                    ll += np.log(pred_s[:, l][idx][0]+0.00001)\n",
    "\n",
    "\n",
    "        return -ll # since we are minimizing the negative log likelihood\n",
    "\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        num_features = len(self.get_features(0, 1))\n",
    "\n",
    "        # additional weights for subhistories\n",
    "\n",
    "        params = np.random.random(num_features*num_features+1)\n",
    "        bnds = [(0, None) for i in range(params.shape[0]-1)]\n",
    "        bnds.append((0, 10))\n",
    "    \n",
    "\n",
    "        result = minimize(\n",
    "            self.log_likelihood ,\n",
    "            params, \n",
    "            bounds = bnds,\n",
    "            args=(dataset)) \n",
    "      \n",
    "        print(result)\n",
    "        assert result.status == 0 # make sure the optimization was successful\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "    def get_features(self, player, lambda_):\n",
    "        '''\n",
    "        returns a set of linear_4 like features\n",
    "        '''\n",
    "\n",
    "        def strat(a):\n",
    "            nonlocal lambda_\n",
    "            weight = 1/len(a)\n",
    "            s = np.zeros(2)\n",
    "            for a_ in a:\n",
    "                s[a_] = weight\n",
    "            return softmax(s*lambda_)\n",
    "\n",
    "        payoffs = self.payoffs\n",
    "\n",
    "        other_player = 1-player\n",
    "\n",
    "\n",
    "        # Problem: if, between switches, \n",
    "\n",
    "\n",
    "        def all_argmax(a):\n",
    "            return np.argwhere(a == np.amax(a)).flatten().tolist()\n",
    "\n",
    "        def all_argmin(a):\n",
    "            return np.argwhere(a == np.amin(a)).flatten().tolist()\n",
    "\n",
    "\n",
    "        if player == 0:\n",
    "            max_min = strat(all_argmax(np.min(payoffs[player], axis=1)))\n",
    "            max_max = strat(all_argmax(np.max(payoffs[player], axis=1)))\n",
    "            min_max = strat(all_argmin(np.max(payoffs[other_player], axis=1)))\n",
    "            \n",
    "            eff = strat(all_argmax(np.max(payoffs[player] + payoffs[other_player], axis=1)))\n",
    "            fair = strat(all_argmin(np.min( np.abs(payoffs[player] - payoffs[other_player]), axis=1)))\n",
    "\n",
    "        else:\n",
    "            max_min = strat(all_argmax(np.min(payoffs[player], axis=0)))\n",
    "            max_max = strat(all_argmax(np.max(payoffs[player], axis=0)))\n",
    "            min_max = strat(all_argmin(np.max(payoffs[other_player], axis=0)))\n",
    "            \n",
    "            eff = strat(all_argmax(np.max(payoffs[player] + payoffs[other_player], axis=0)))\n",
    "            fair = strat(all_argmin(np.min( np.abs(payoffs[player] - payoffs[other_player]), axis=0)))\n",
    "\n",
    "        unif = np.ones(2)/2\n",
    "\n",
    "        return [max_min, max_max, min_max, eff, fair, unif]\n",
    "\n",
    "\n",
    "    def hist_to_str(hist):\n",
    "        hist = hist.astype(str).tolist()\n",
    "        return [''.join(elmt) for elmt in hist]\n",
    "\n",
    "\n",
    "    def predict_traj(self, traj, other_traj, M, player,  lambda_, print_=False):\n",
    "        '''\n",
    "        Returns straetgy predictions against other player\n",
    "        \n",
    "        '''\n",
    "        play_len = traj.shape[1]\n",
    "        pred_i = np.zeros((2, play_len))\n",
    "\n",
    "        for l in range(play_len):\n",
    "            if l == 0:\n",
    "                pred_i[:, l] = np.ones(2)/2\n",
    "               \n",
    "            else:\n",
    "                p = self.get_probs(other_traj[:, max(l-self.h, 0):l], 1-player, lambda_) # probability of history under each simple strat\n",
    "               \n",
    "                p = p / np.max(p) # p is the same\n",
    "                w = np.dot(M, p) # w is the same \n",
    "              \n",
    "                features = self.get_features(player, lambda_)  \n",
    "\n",
    "                if print_:\n",
    "                    print(w)\n",
    "                    print(p)\n",
    "                    print(features)\n",
    "                weighted_features = np.zeros((2, len(features)))\n",
    "\n",
    "\n",
    "                sum_w = np.sum(w)\n",
    "                for i in range(len(features)):\n",
    "                    weighted_features[:, i] = features[i] * (w[i]/sum_w)\n",
    "              \n",
    "                pred_i[:, l] = np.sum(np.array(weighted_features), axis = 1)\n",
    "            \n",
    "        return pred_i   \n",
    "\n",
    "\n",
    "\n",
    "    def get_probs(self, hist, player, lambda_):\n",
    "        '''\n",
    "        Returns the probability of a history \n",
    "        '''\n",
    "\n",
    "\n",
    "        def p_traj_single(a, s):\n",
    "            '''\n",
    "            Returns the probability of a sequence of actions\n",
    "            a being sampled from strategy s.\n",
    "\n",
    "            Paramters:\n",
    "                a : (np.Array) 2 x n array of actions chosen\n",
    "                s : (np.Array) 2 x 1 strategy\n",
    "            '''\n",
    "            L = a.shape[1]\n",
    "            prod = 1\n",
    "            for l in range(L):\n",
    "                idx = np.where(a[:, l])\n",
    "                prod *= s[idx][0]\n",
    "\n",
    "            return prod\n",
    "\n",
    "        features = self.get_features(player, lambda_)\n",
    "        probs = np.zeros(len(features))\n",
    "        avg_h = np.mean(hist, axis=1 )\n",
    "       \n",
    "        for i, s in enumerate(features):\n",
    "            probs[i] = p_traj_single(hist, s)\n",
    "\n",
    "        return probs\n",
    "\n",
    "\n",
    "    def compute_BR(self,  s_other, lambda_):\n",
    "        '''\n",
    "        Computes a best response\n",
    "\n",
    "        Parameters:\n",
    "            s_other : (np.Array) strategy of other player\n",
    "\n",
    "        NOTE: this ONLY works with symetric payoffs and 2 actions\n",
    "        '''\n",
    "    \n",
    "        #get EU of action 0\n",
    "        s = [np.array([1, 0]), s_other]\n",
    "        eu_0 = expected_utility(s, self.payoffs[0])\n",
    "\n",
    "        # get EU of action 1\n",
    "        s = [np.array([0, 1]), s_other]\n",
    "        eu_1 = expected_utility(s, self.payoffs[0])\n",
    "\n",
    "        # return action with greater EU\n",
    "        return softmax(np.array([eu_0, eu_1])*lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Bounded_Memory_Map(2)\n",
    "r = m.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.,  0.],\n",
       "        [-2.,  1.]],\n",
       "\n",
       "       [[ 1.,  0.],\n",
       "        [-2., -1.]]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = deepcopy(m)\n",
    "m2.payoffs[0][:, [0, 1]] = m.payoffs[0][:, [1, 0]]\n",
    "m2.payoffs[1][:, [0, 1]] = m.payoffs[1][:, [1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.125, 0.125])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_probs(new_data[1][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.125, 0.125])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_probs(data[1][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip actions for player 1\n",
    "\n",
    "from copy import deepcopy\n",
    "new_data = deepcopy(data)\n",
    "for play in new_data:\n",
    "    # for p in range(2):\n",
    "    #play[0][[0, 1]] = play[0][[1, 0]]\n",
    "    play[1][[0, 1]] = play[1][ [1, 0]]\n",
    "   # play[1][ [0, 1], :] = play[1][ [1, 0], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 1, 1, 1, 0],\n",
       "        [1, 0, 0, 0, 1]]),\n",
       " array([[1, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 1, 1]])]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 1, 1, 1, 0],\n",
       "        [1, 0, 0, 0, 1]]),\n",
       " array([[0, 1, 0, 1, 1],\n",
       "        [1, 0, 1, 0, 0]])]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.88443463824265"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.log_likelihood(r.x, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.,  0.],\n",
       "        [-2.,  1.]],\n",
       "\n",
       "       [[ 1.,  0.],\n",
       "        [-2., -1.]]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.payoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.88443463824265"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.log_likelihood(r.x, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.66095402 0.88219117 0.45197306]\n",
      "[1.  0.  0.5]\n",
      "[array([1., 0.]), array([0., 1.]), array([0.5, 0.5])]\n",
      "[0.21946011 1.67593238 0.74440842]\n",
      "[0.  1.  0.5]\n",
      "[array([1., 0.]), array([0., 1.]), array([0.5, 0.5])]\n",
      "[1.66095402 0.88219117 0.45197306]\n",
      "[1.  0.  0.5]\n",
      "[array([1., 0.]), array([0., 1.]), array([0.5, 0.5])]\n",
      "[0.21946011 1.67593238 0.74440842]\n",
      "[0.  1.  0.5]\n",
      "[array([1., 0.]), array([0., 1.]), array([0.5, 0.5])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.63000536, 0.22413217, 0.63000536, 0.22413217],\n",
       "       [0.5       , 0.36999464, 0.77586783, 0.36999464, 0.77586783]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict_traj(data[0][0], data[0][1], r.x.reshape((3,3)), 0, print_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.66095402 0.88219117 0.45197306]\n",
      "[1.  0.  0.5]\n",
      "[array([0., 1.]), array([1., 0.]), array([0.5, 0.5])]\n",
      "[0.21946011 1.67593238 0.74440842]\n",
      "[0.  1.  0.5]\n",
      "[array([0., 1.]), array([1., 0.]), array([0.5, 0.5])]\n",
      "[1.66095402 0.88219117 0.45197306]\n",
      "[1.  0.  0.5]\n",
      "[array([0., 1.]), array([1., 0.]), array([0.5, 0.5])]\n",
      "[0.21946011 1.67593238 0.74440842]\n",
      "[0.  1.  0.5]\n",
      "[array([0., 1.]), array([1., 0.]), array([0.5, 0.5])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.36999464, 0.77586783, 0.36999464, 0.77586783],\n",
       "       [0.5       , 0.63000536, 0.22413217, 0.63000536, 0.22413217]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.predict_traj(new_data[0][0], new_data[0][1], r.x.reshape((3,3)), 0, print_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1., -2.],\n",
       "        [ 0., -1.]],\n",
       "\n",
       "       [[-1., -2.],\n",
       "        [ 0.,  1.]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.payoffs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "174d5a967417a2ba15b92fee30b6658756f13acfa6c5a4bc13885d05104c7799"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('bgt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
