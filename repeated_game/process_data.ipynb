{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils \n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.optimize import minimize, LinearConstraint\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('repeated_data.csv', delimiter=',', dtype=str)\n",
    "data = np.delete(data, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "# turn each game into entry in this array\n",
    "\n",
    "def remove_blank(l):\n",
    "    return list(filter(lambda a: a != '', l))\n",
    "\n",
    "def replace_letters(l):\n",
    "   return [[1,0] if x=='c' else [0, 1] for x in l]\n",
    "\n",
    "for i in range(0, data.shape[0], 2):\n",
    "    p1 = data[i]\n",
    "    p2 = data[i+1]\n",
    "\n",
    "    game = int(p1[0])\n",
    "    player1 = p1[2]\n",
    "    player2 = p2[2]\n",
    "    p1_actions = np.array(replace_letters(remove_blank(p1[3:]))).T\n",
    "    p2_actions =  np.array(replace_letters(remove_blank(p2[3:]))).T\n",
    "   \n",
    "    actions =  [p1_actions, p2_actions]\n",
    "\n",
    "    new_data.append([game, player1, player2, actions])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_data)\n",
    "df.columns = ['Game', 'Player_1', 'Player_2', 'Actions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Player_1</th>\n",
       "      <th>Player_2</th>\n",
       "      <th>Actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Faisal</td>\n",
       "      <td>Bharathvaj</td>\n",
       "      <td>[[[0, 1, 1, 1, 0], [1, 0, 0, 0, 1]], [[1, 0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yuan</td>\n",
       "      <td>Dagmar</td>\n",
       "      <td>[[[1, 0, 0], [0, 1, 1]], [[1, 1, 0], [0, 0, 1]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ehsan</td>\n",
       "      <td>Mohammend</td>\n",
       "      <td>[[[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tao</td>\n",
       "      <td>Rohini</td>\n",
       "      <td>[[[0, 1, 0, 1, 1], [1, 0, 1, 0, 0]], [[1, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Anita</td>\n",
       "      <td>Greg</td>\n",
       "      <td>[[[1, 1, 0, 1, 1, 1, 0], [0, 0, 1, 0, 0, 0, 1]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Game Player_1    Player_2  \\\n",
       "0     0   Faisal  Bharathvaj   \n",
       "1     1    Yuan       Dagmar   \n",
       "2     2    Ehsan   Mohammend   \n",
       "3     3      Tao      Rohini   \n",
       "4     4    Anita        Greg   \n",
       "\n",
       "                                             Actions  \n",
       "0  [[[0, 1, 1, 1, 0], [1, 0, 0, 0, 1]], [[1, 0, 1...  \n",
       "1   [[[1, 0, 0], [0, 1, 1]], [[1, 1, 0], [0, 0, 1]]]  \n",
       "2  [[[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0], [0, 0,...  \n",
       "3  [[[0, 1, 0, 1, 1], [1, 0, 1, 0, 0]], [[1, 0, 0...  \n",
       "4  [[[1, 1, 0, 1, 1, 1, 0], [0, 0, 1, 0, 0, 0, 1]...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30232558, 0.18604651],\n",
       "       [0.26744186, 0.24418605]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plays = np.zeros((2,2))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    actions = row.Actions\n",
    "    for round in range( actions[0].shape[1]): # iterate over length of each game \n",
    "        s1 = actions[0][:, round]\n",
    "        s2 = actions[1][:, round]\n",
    "        p_outcomes = utils.p_outcomes([s1, s2])\n",
    "        plays += p_outcomes\n",
    "      \n",
    "# frequency of each\n",
    "plays/np.sum(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis_labels = ['Cautious', 'Free']\n",
    "y_axis_labels = ['Cautious', 'Free']\n",
    "sns.set(font_scale=2) \n",
    "sns.heatmap(plays/np.sum(plays), annot=True, cbar=False, xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_traj(a, s):\n",
    "    '''\n",
    "    Returns the probability of a sequence of actions\n",
    "    a being sampled from strategy s.\n",
    "\n",
    "    Paramters:\n",
    "        a : (np.Array) 2 x n array of actions chosen\n",
    "        s : (np.Array) 2 x n array of strategies \n",
    "    '''\n",
    "\n",
    "    assert a.shape == s.shape\n",
    "    L = a.shape[1]\n",
    "    prod = 1\n",
    "    for l in range(L):\n",
    "        idx = np.where(a[:, l])\n",
    "        prod *= s[:, l][idx][0]\n",
    "\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(df.Actions)\n",
    "traj = data[0][0][:, 0:3]\n",
    "s = np.array([[0.9, 0.1], [0.6, 0.4], [.3, .7] ]).T\n",
    "assert p_traj(traj, s) == 0.018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_outcomes(s):\n",
    "    '''\n",
    "    returns a probability distribution over outcomes\n",
    "    '''\n",
    "    p = s[0]\n",
    "    for s_i in s[1:]:\n",
    "        p =  np.multiply.outer(p, s_i)\n",
    "    return p\n",
    "\n",
    "def expected_utility(s, payoffs):\n",
    "    '''\n",
    "    Gets the expected utilitiy for a player under strategy profile s\n",
    "    \n",
    "    Parameters\n",
    "        s : (list) list where S[i] gives the probability of player i playing each action\n",
    "        payoffs: (np.array) payoffs for i\n",
    "    Returns\n",
    "        eu : (float) expected utility for i\n",
    "    '''\n",
    "    p = p_outcomes(s)\n",
    "    return np.sum(np.multiply(p, payoffs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(3)[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((2, 8)) / (np.ones(8)*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-119.2213150563106"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ll_uniform( dataset):\n",
    "    ll = 0\n",
    "    for play in dataset: \n",
    "        for player in range(2):\n",
    "            traj = play[player]\n",
    "            s = np.ones_like(traj) / np.ones(traj.shape[1])*2\n",
    "            ll += np.log(p_traj(traj, s))\n",
    "    return -ll\n",
    "\n",
    "ll_uniform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Level_K_Model:\n",
    "    def __init__(self, K, h):\n",
    "        self.K = K\n",
    "        self.payoffs = np.zeros([2, 2, 2])\n",
    "        self.payoffs[0, :, :] = np.array([[0, -1],\n",
    "                                          [1, -2]])\n",
    "        self.payoffs[1, :, :] = np.array([[0, 1],\n",
    "                                         [-1, -2]])\n",
    "        self.alphas = None\n",
    "        self.h = h # the history length\n",
    "\n",
    "\n",
    "    def log_likelihood_independent(self, params, dataset):\n",
    "        '''\n",
    "        Given the dataset and the fitted model, returns the log likelihood. This assumes a players level may change as the game goes on\n",
    "\n",
    "        NOTE: assumes each player has a fixed level\n",
    "        \n",
    "        Parameters:\n",
    "            params : np.array of alpha_ks, the freq of that level in population and lambda_ for QBR\n",
    "            dataset : list of plays, each play is an np array\n",
    "        Returns:\n",
    "            ll : loglikelihood of dataset\n",
    "\n",
    "        '''\n",
    "        \n",
    "        alphas = params[0:-1]\n",
    "        lambda_ = params[-1] \n",
    "\n",
    "        ll = 0\n",
    "        for play in dataset: \n",
    "            for player in range(2):\n",
    "                    traj = play[player]\n",
    "                    other_traj  = play[1-player] # trajectory of other player\n",
    "                    \n",
    "                    pred_s = self.predict_traj(traj, other_traj, self.K, lambda_, overall=True, alphas=alphas)  \n",
    "                    L = traj.shape[1] #length of trajectory\n",
    "                 \n",
    "                    for l in range(L):\n",
    "                        idx = np.where(traj[:, l])\n",
    "                        ll += np.log(pred_s[:, l][idx][0]+0.0001)\n",
    "\n",
    "    \n",
    "        return -ll # since we are minimizing the negative log likelihood\n",
    "\n",
    "\n",
    "\n",
    "    def log_likelihood(self, params, dataset):\n",
    "        '''\n",
    "        Given the dataset and the fitted model, returns the log likelihood.\n",
    "\n",
    "        NOTE: assumes each player has a fixed level\n",
    "        \n",
    "        Parameters:\n",
    "            params : np.array of alpha_ks, the freq of that level in population and lambda_ for QBR\n",
    "            dataset : list of plays, each play is an np array\n",
    "        Returns:\n",
    "            ll : loglikelihood of dataset\n",
    "\n",
    "        '''\n",
    "        alphas = params[0:-2]\n",
    "        lambda_ = params[-2] \n",
    "        kappa  = params[-1] \n",
    "       \n",
    "\n",
    "        ll = 0\n",
    "        for play in dataset: \n",
    "            for player in range(2):\n",
    "                sum = 0\n",
    "                for i, k in enumerate(range(self.K+1)): # condition on a specific value of k for a player\n",
    "                    alpha_k = alphas[i]\n",
    "    \n",
    "                    traj = play[player]\n",
    "                    other_traj  = play[1-player] # trajectory of other player\n",
    "                    pred_s = self.predict_traj(traj, other_traj, k, lambda_, kappa)\n",
    "                    \n",
    "                    prob = p_traj(traj, pred_s) # probability of that trajectory\n",
    "                    \n",
    "                    sum += alpha_k * prob # this could be 0, so small epsilon added\n",
    "\n",
    "                ll += np.log(sum)\n",
    "                #print(np.log(sum))\n",
    "\n",
    "        return -ll # since we are minimizing the negative log likelihood\n",
    "\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        params = np.zeros(self.K+3) # +2 since level 0 and the lambda parameter, kappa parameter\n",
    "        params[0] = 1 # inital guess is that all players are level 0\n",
    "        params[-2] = 5 # intial guess for lambda\n",
    "        params[-1] = 0.5 # intial guess for kappa\n",
    "\n",
    "        const_arr = np.ones(self.K+3)\n",
    "        const_arr[-1] = 0\n",
    "        const_arr[-2] = 0\n",
    "        #print(const_arr)\n",
    "        constraint = LinearConstraint(const_arr, lb=1, ub=1)\n",
    "        bnds = [(0, 1) for x in range(self.K+1)]\n",
    "        bnds.append((0, 1000)) \n",
    "        bnds.append((0, 1)) \n",
    "        #print(bnds)\n",
    "\n",
    "        result = minimize(\n",
    "            self.log_likelihood ,\n",
    "            params, \n",
    "            args=(dataset),\n",
    "            bounds=bnds, \n",
    "            constraints=constraint) \n",
    "        print(result)\n",
    "\n",
    "        assert result.status == 0 # make sure the optimization was successful\n",
    "        self.alphas = result.x[0:-1]\n",
    "        self.lambda_ = result.x[-1]\n",
    "        ll = result.fun\n",
    "        return ll\n",
    "\n",
    "\n",
    "    def predict_traj(self, traj, other_traj, K, lambda_, kappa, overall=False, alphas=None):\n",
    "        '''\n",
    "        Returns straetgy predictions against other player\n",
    "        \n",
    "        '''\n",
    "        def get_weights(h, kappa):\n",
    "            if h == 1:\n",
    "                return np.ones(1)\n",
    "            \n",
    "            l = [1-kappa]\n",
    "            for i in range(1, h-1):\n",
    "                l.append(l[i-1]*kappa)\n",
    "\n",
    "            l.append(1- np.sum(l))\n",
    "            assert np.sum(l) == 1\n",
    "            return np.flip(np.array(l)) # should be flipped\n",
    "\n",
    "        L = other_traj.shape[1]\n",
    "        pred_i = np.zeros((2, self.K+1, L)) # level-k prediction for each stage game for i\n",
    "        pred_other = np.zeros((2, self.K+1, L)) # level-k prediction for each stage game for other player\n",
    "\n",
    "        for l in range(L):\n",
    "            # first determine level 0 strategy \n",
    "            start_hist_idx = max(l-self.h, 0)\n",
    "            end_hist_idx = l\n",
    "\n",
    "            if l == 0: # there is no history, so level-0 strategies are uniform\n",
    "                lvl_0_s_i = np.ones((2)) / 2\n",
    "                lvl_0_s_other = np.ones((2)) / 2\n",
    "            else:\n",
    "                hist_i = traj[:, start_hist_idx:end_hist_idx] # limited history of i's actions\n",
    "                hist_other = other_traj[:, start_hist_idx:end_hist_idx] # limited history of -i's actions\n",
    "\n",
    "                w = get_weights(hist_i.shape[1], kappa)\n",
    "                lvl_0_s_i = np.dot(hist_i, w)\n",
    "                lvl_0_s_other= np.dot(hist_other, w)\n",
    "\n",
    "\n",
    "            # These become the level 0 strategies\n",
    "            pred_i[:, 0, l] = lvl_0_s_i\n",
    "            pred_other[:, 0, l] = lvl_0_s_other\n",
    "\n",
    "            # Now, for higher levels:\n",
    "            for k in range(1, K+1):\n",
    "                pred_i[:, k, l] = self.compute_BR(pred_other[:, k-1, l], lambda_)\n",
    "                pred_other[:, k, l] = self.compute_BR(pred_i[:, k-1, l], lambda_)\n",
    " \n",
    "\n",
    "        if overall: # if return the overall prediction\n",
    "            assert alphas is not None\n",
    "            pred_i_ = np.zeros((2, L))\n",
    "\n",
    "            for l in range(L):\n",
    "                pred_i_[:, l] = np.matmul(pred_i[:, :, l], alphas)\n",
    "            pred_i = pred_i_\n",
    "     \n",
    "        else:\n",
    "            pred_i = np.squeeze(pred_i[:, K, :]) # only return the level K predictions\n",
    "\n",
    "\n",
    "        if K == 0:\n",
    "            return np.ones((2, L)) / (np.ones(L)*2)\n",
    "        else:\n",
    "            return pred_i   \n",
    "        \n",
    "        \n",
    "    def predict_traj_new(self, traj, other_traj, K, lambda_, overall=False, alphas=None, gamma=0.5): \n",
    "        '''\n",
    "        sdfsd\n",
    "        \n",
    "        '''\n",
    "        L = other_traj.shape[1]\n",
    "        pred_i = np.zeros((2, L)) # level-k prediction for each stage game for i\n",
    "        pred_other = np.zeros((2, L)) # level-k prediction for each stage game for other player\n",
    "\n",
    "        def level_k_strat(lvl_0_p0, lvl_0_p1, k):\n",
    "\n",
    "            nonlocal lambda_\n",
    "            if k == 0:\n",
    "                return [lvl_0_p0, lvl_0_p1]\n",
    "\n",
    "            lvl_kminus1_p0 = lvl_0_p0\n",
    "            lvl_kminus1_p1 = lvl_0_p1\n",
    "            for k in range(1, k+1):\n",
    "                lvl_k_p0 = self.compute_BR(lvl_kminus1_p1, lambda_)\n",
    "                lvl_k_p1 = self.compute_BR(lvl_kminus1_p0, lambda_)\n",
    "                lvl_kminus1_p0 = lvl_k_p0\n",
    "                lvl_kminus1_p1 = lvl_k_p1\n",
    "\n",
    "            return [lvl_k_p0, lvl_k_p1]\n",
    "\n",
    "\n",
    "        for l in range(L):\n",
    "            # first determine level 0 strategy \n",
    "            # for each action, compute BR in next round assuming opponent level-k responds\n",
    "            \n",
    "            # if action 0\n",
    "\n",
    "            if l == 0:\n",
    "                next_s = level_k_strat(np.array([1,0]), np.array([0.5, 0.5]), K) # could replace this with history?\n",
    "                eu_0 = expected_utility([np.array([1,0]), np.array([0.5, 0.5])], self.payoffs[0]) + gamma*expected_utility([next_s[0], next_s[1]], self.payoffs[0])\n",
    "\n",
    "                # if action 1\n",
    "                next_s = level_k_strat(np.array([0,1]), np.array([0.5, 0.5]), K)\n",
    "                eu_1 =  expected_utility([np.array([0,1]), np.array([0.5, 0.5])], self.payoffs[0])+ gamma*expected_utility([next_s[0], next_s[1]], self.payoffs[0])\n",
    "           \n",
    "            else:\n",
    "            \n",
    "                s_this = level_k_strat(traj[:, l-1], other_traj[:, l-1], K)\n",
    "\n",
    "                next_s = level_k_strat(np.array([1,0]), s_this[1], K)  \n",
    "                eu_0 = expected_utility([np.array([1,0]), s_this[1] ], self.payoffs[0]) + gamma*expected_utility([next_s[0], next_s[1]], self.payoffs[0])\n",
    "\n",
    "                # if action 1\n",
    "                next_s = level_k_strat(np.array([0,1]), s_this[1], K) \n",
    "                eu_1 = expected_utility([np.array([0,1]), s_this[1]], self.payoffs[0]) + gamma*expected_utility([next_s[0], next_s[1]], self.payoffs[0]) \n",
    "    \n",
    "\n",
    "            pred_i[:, l]  = softmax(lambda_* np.array([eu_0, eu_1]))\n",
    "        return pred_i   \n",
    "\n",
    "    def compute_BR(self,  s_other, lambda_):\n",
    "        '''\n",
    "        Computes a best response\n",
    "\n",
    "        Parameters:\n",
    "            s_other : (np.Array) strategy of other player\n",
    "\n",
    "        NOTE: this ONLY works with symetric payoffs and 2 actions\n",
    "        '''\n",
    "    \n",
    "        #get EU of action 0\n",
    "    \n",
    "        s = [np.array([1, 0]), s_other]\n",
    "        eu_0 = expected_utility(s, self.payoffs[0])\n",
    "        #print('EU 0: {}'.format( eu_0))\n",
    "\n",
    "        # get EU of action 1\n",
    "        s = [np.array([0, 1]), s_other]\n",
    "        eu_1 = expected_utility(s, self.payoffs[0])\n",
    "\n",
    "        #print('EU 1: {}'.format( eu_1))\n",
    "\n",
    "        # return action with greater EU\n",
    "        return softmax(np.array([eu_0, eu_1])*lambda_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.46976339824258"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Level_K_Model(2, 2)\n",
    "\n",
    "m.log_likelihood([1/2, 1/2, , 1, 0.7], data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 119.2213150563106\n",
      "     jac: array([-28.        , -12.06767845, -27.84967232,   0.        ,\n",
      "         0.        ])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 6\n",
      "     nit: 1\n",
      "    njev: 1\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([1. , 0. , 0. , 5. , 0.5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = Level_K_Model(2, 2)\n",
    "ll = m.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.64494106, 0.45104967, 0.58638233, 0.41361767],\n",
       "       [0.5       , 0.35505894, 0.54895033, 0.41361767, 0.58638233]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = data[0][0]\n",
    "t2 = data[0][1]\n",
    "m.predict_traj(t2, t1, 2, 1.15, 0.65 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 119.2213150563106\n",
      "     jac: array([-28.        , -15.49908161,   0.        ,   0.        ])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 5\n",
      "     nit: 1\n",
      "    njev: 1\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([1. , 0. , 5. , 0.5])\n",
      "     fun: 115.4884639062245\n",
      "     jac: array([-2.76285419e+01, -1.63381367e+01, -2.80000000e+01, -2.86102295e-05,\n",
      "        6.96182251e-05])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 176\n",
      "     nit: 28\n",
      "    njev: 28\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.00000000e+00, 2.07195658e-13, 1.00000000e+00, 1.15683749e+00,\n",
      "       7.31512559e-01])\n",
      "     fun: 115.48846390638656\n",
      "     jac: array([-2.76286030e+01, -1.63381386e+01, -2.80000000e+01, -2.32745676e+01,\n",
      "        9.44137573e-05,  4.95910645e-05])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 197\n",
      "     nit: 27\n",
      "    njev: 27\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.09190665e-13, 0.00000000e+00, 1.00000000e+00, 1.46131390e-15,\n",
      "       1.15684462e+00, 7.31511180e-01])\n",
      "     fun: 119.2213150563106\n",
      "     jac: array([-28.        , -15.40947819,   0.        ,   0.        ])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 5\n",
      "     nit: 1\n",
      "    njev: 1\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([1. , 0. , 5. , 0.5])\n",
      "     fun: 115.36189595655054\n",
      "     jac: array([-2.79189320e+01, -1.64079695e+01, -2.80000010e+01,  8.64028931e-04,\n",
      "        3.31878662e-04])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 166\n",
      "     nit: 26\n",
      "    njev: 26\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.00000000e+00, 1.34360390e-13, 1.00000000e+00, 1.16853119e+00,\n",
      "       7.33615757e-01])\n",
      "     fun: 115.36189596213386\n",
      "     jac: array([-2.79189920e+01, -1.64079561e+01, -2.80000000e+01, -2.34369478e+01,\n",
      "        9.76562500e-04,  3.55720520e-04])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 192\n",
      "     nit: 26\n",
      "    njev: 26\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.00000000e+00, 1.01115705e-13, 1.00000000e+00, 0.00000000e+00,\n",
      "       1.16853716e+00, 7.33615987e-01])\n",
      "     fun: 119.2213150563106\n",
      "     jac: array([-28.        , -15.37907124,   0.        ,   0.        ])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 5\n",
      "     nit: 1\n",
      "    njev: 1\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([1. , 0. , 5. , 0.5])\n",
      "     fun: 115.77371021049373\n",
      "     jac: array([-2.78598967e+01, -1.59145947e+01, -2.80000000e+01,  8.26835632e-04,\n",
      "        1.68132782e-03])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 237\n",
      "     nit: 37\n",
      "    njev: 37\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.00000000e+00, 1.39503929e-16, 1.00000000e+00, 1.11701206e+00,\n",
      "       8.07739741e-01])\n",
      "     fun: 115.77371017202152\n",
      "     jac: array([-2.78595095e+01, -1.59148998e+01, -2.80000000e+01, -2.36018896e+01,\n",
      "       -5.72204590e-06,  5.09262085e-04])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 206\n",
      "     nit: 29\n",
      "    njev: 28\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([8.11226198e-13, 0.00000000e+00, 1.00000000e+00, 6.01921072e-15,\n",
      "       1.11697430e+00, 8.07718796e-01])\n",
      "     fun: 119.2213150563106\n",
      "     jac: array([-28.        , -15.37895012,   0.        ,   0.        ])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 5\n",
      "     nit: 1\n",
      "    njev: 1\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([1. , 0. , 5. , 0.5])\n",
      "     fun: 115.75504486327375\n",
      "     jac: array([-2.79143553e+01, -1.58017044e+01, -2.80000010e+01, -1.10626221e-04,\n",
      "       -3.58295441e-03])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 178\n",
      "     nit: 29\n",
      "    njev: 28\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.00000000e+00, 9.50180491e-14, 1.00000000e+00, 1.12386967e+00,\n",
      "       8.10372910e-01])\n",
      "     fun: 115.7550446995008\n",
      "     jac: array([-2.79143991e+01, -1.58009491e+01, -2.80000000e+01, -2.35211039e+01,\n",
      "        2.03132629e-04, -1.59263611e-04])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 281\n",
      "     nit: 38\n",
      "    njev: 38\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.74759770e-11,\n",
      "       1.12385698e+00, 8.10459857e-01])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000021?line=3'>4</a>\u001b[0m m \u001b[39m=\u001b[39m Level_K_Model(k, h)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000021?line=5'>6</a>\u001b[0m \u001b[39m#m.log_likelihood([1/2, 1/2, 0, 1, 0.7], data)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000021?line=6'>7</a>\u001b[0m ll \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mfit(data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000021?line=7'>8</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(ll)\n",
      "\u001b[1;32m/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb Cell 15'\u001b[0m in \u001b[0;36mLevel_K_Model.fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=101'>102</a>\u001b[0m bnds\u001b[39m.\u001b[39mappend((\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)) \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=102'>103</a>\u001b[0m \u001b[39m#print(bnds)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=104'>105</a>\u001b[0m result \u001b[39m=\u001b[39m minimize(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=105'>106</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_likelihood ,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=106'>107</a>\u001b[0m     params, \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=107'>108</a>\u001b[0m     args\u001b[39m=\u001b[39;49m(dataset),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=108'>109</a>\u001b[0m     bounds\u001b[39m=\u001b[39;49mbnds, \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=109'>110</a>\u001b[0m     constraints\u001b[39m=\u001b[39;49mconstraint) \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=110'>111</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=112'>113</a>\u001b[0m \u001b[39massert\u001b[39;00m result\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39m# make sure the optimization was successful\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_minimize.py:690\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=686'>687</a>\u001b[0m     res \u001b[39m=\u001b[39m _minimize_cobyla(fun, x0, args, constraints, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=687'>688</a>\u001b[0m                             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=688'>689</a>\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mslsqp\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=689'>690</a>\u001b[0m     res \u001b[39m=\u001b[39m _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=690'>691</a>\u001b[0m                           constraints, callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=691'>692</a>\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrust-constr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=692'>693</a>\u001b[0m     res \u001b[39m=\u001b[39m _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=693'>694</a>\u001b[0m                                        bounds, constraints,\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=694'>695</a>\u001b[0m                                        callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_slsqp_py.py:374\u001b[0m, in \u001b[0;36m_minimize_slsqp\u001b[0;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_slsqp_py.py?line=370'>371</a>\u001b[0m     xu[infbnd[:, \u001b[39m1\u001b[39m]] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_slsqp_py.py?line=372'>373</a>\u001b[0m \u001b[39m# ScalarFunction provides function and gradient evaluation\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_slsqp_py.py?line=373'>374</a>\u001b[0m sf \u001b[39m=\u001b[39m _prepare_scalar_function(func, x, jac\u001b[39m=\u001b[39;49mjac, args\u001b[39m=\u001b[39;49margs, epsilon\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_slsqp_py.py?line=374'>375</a>\u001b[0m                               finite_diff_rel_step\u001b[39m=\u001b[39;49mfinite_diff_rel_step,\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_slsqp_py.py?line=375'>376</a>\u001b[0m                               bounds\u001b[39m=\u001b[39;49mnew_bounds)\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_slsqp_py.py?line=376'>377</a>\u001b[0m \u001b[39m# gh11403 SLSQP sometimes exceeds bounds by 1 or 2 ULP, make sure this\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_slsqp_py.py?line=377'>378</a>\u001b[0m \u001b[39m# doesn't get sent to the func/grad evaluator.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_slsqp_py.py?line=378'>379</a>\u001b[0m wrapped_fun \u001b[39m=\u001b[39m _clip_x_for_func(sf\u001b[39m.\u001b[39mfun, new_bounds)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_optimize.py:263\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=258'>259</a>\u001b[0m     bounds \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf)\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=260'>261</a>\u001b[0m \u001b[39m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=261'>262</a>\u001b[0m \u001b[39m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=262'>263</a>\u001b[0m sf \u001b[39m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=263'>264</a>\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[39m=\u001b[39;49mepsilon)\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=265'>266</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:177\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=172'>173</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg \u001b[39m=\u001b[39m approx_derivative(fun_wrapped, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx, f0\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf,\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=173'>174</a>\u001b[0m                                    \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfinite_diff_options)\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=175'>176</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad_impl \u001b[39m=\u001b[39m update_grad\n\u001b[0;32m--> <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=176'>177</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad()\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=178'>179</a>\u001b[0m \u001b[39m# Hessian Evaluation\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=179'>180</a>\u001b[0m \u001b[39mif\u001b[39;00m callable(hess):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=253'>254</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_grad\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=254'>255</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated:\n\u001b[0;32m--> <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=255'>256</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad_impl()\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=256'>257</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=170'>171</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=171'>172</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=172'>173</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg \u001b[39m=\u001b[39m approx_derivative(fun_wrapped, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, f0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf,\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=173'>174</a>\u001b[0m                            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfinite_diff_options)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=501'>502</a>\u001b[0m     use_one_sided \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=503'>504</a>\u001b[0m \u001b[39mif\u001b[39;00m sparsity \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=504'>505</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=505'>506</a>\u001b[0m                              use_one_sided, method)\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=506'>507</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=507'>508</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(sparsity) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(sparsity) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=573'>574</a>\u001b[0m     x \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=574'>575</a>\u001b[0m     dx \u001b[39m=\u001b[39m x[i] \u001b[39m-\u001b[39m x0[i]  \u001b[39m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=575'>576</a>\u001b[0m     df \u001b[39m=\u001b[39m fun(x) \u001b[39m-\u001b[39m f0\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=576'>577</a>\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m3-point\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=577'>578</a>\u001b[0m     x1 \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=454'>455</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=455'>456</a>\u001b[0m     f \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_1d(fun(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=456'>457</a>\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=457'>458</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`fun` return value has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_numdiff.py?line=458'>459</a>\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mmore than 1 dimension.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=132'>133</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=133'>134</a>\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=134'>135</a>\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=135'>136</a>\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=136'>137</a>\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=137'>138</a>\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/RevanMacQueen/opt/anaconda3/envs/bgt/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=138'>139</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "\u001b[1;32m/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb Cell 15'\u001b[0m in \u001b[0;36mLevel_K_Model.log_likelihood\u001b[0;34m(self, params, dataset)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=72'>73</a>\u001b[0m traj \u001b[39m=\u001b[39m play[player]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=73'>74</a>\u001b[0m other_traj  \u001b[39m=\u001b[39m play[\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mplayer] \u001b[39m# trajectory of other player\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=76'>77</a>\u001b[0m pred_s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_traj(traj, other_traj, k, lambda_, kappa)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=78'>79</a>\u001b[0m prob \u001b[39m=\u001b[39m p_traj(traj, pred_s) \u001b[39m# probability of that trajectory\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=80'>81</a>\u001b[0m \u001b[39msum\u001b[39m \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m alpha_k \u001b[39m*\u001b[39m prob \u001b[39m# this could be 0, so small epsilon added\u001b[39;00m\n",
      "\u001b[1;32m/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb Cell 15'\u001b[0m in \u001b[0;36mLevel_K_Model.predict_traj\u001b[0;34m(self, traj, other_traj, K, lambda_, kappa, overall, alphas)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=149'>150</a>\u001b[0m hist_i \u001b[39m=\u001b[39m traj[:, start_hist_idx:end_hist_idx] \u001b[39m# limited history of i's actions\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=150'>151</a>\u001b[0m hist_other \u001b[39m=\u001b[39m other_traj[:, start_hist_idx:end_hist_idx] \u001b[39m# limited history of -i's actions\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=152'>153</a>\u001b[0m w \u001b[39m=\u001b[39m get_weights(hist_i\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], kappa)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=153'>154</a>\u001b[0m lvl_0_s_i \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(hist_i, w)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=154'>155</a>\u001b[0m lvl_0_s_other\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(hist_other, w)\n",
      "\u001b[1;32m/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb Cell 15'\u001b[0m in \u001b[0;36mLevel_K_Model.predict_traj.<locals>.get_weights\u001b[0;34m(h, kappa)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=130'>131</a>\u001b[0m     l\u001b[39m.\u001b[39mappend(l[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39mkappa)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=132'>133</a>\u001b[0m l\u001b[39m.\u001b[39mappend(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m np\u001b[39m.\u001b[39msum(l))\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=133'>134</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39msum(l) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/RevanMacQueen/Projects/BGT-Project/repeated_game/process_data.ipynb#ch0000016?line=134'>135</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(l)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for h in range(4, 10):\n",
    "    for k in range(1, 4):\n",
    "        m = Level_K_Model(k, h)\n",
    "\n",
    "        #m.log_likelihood([1/2, 1/2, 0, 1, 0.7], data)\n",
    "        ll = m.fit(data)\n",
    "        losses.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CH_Model(Level_K_Model):\n",
    "\n",
    "    def log_likelihood(self, params, dataset):\n",
    "        '''\n",
    "        Given the dataset and the fitted model, returns the log likelihood.\n",
    "\n",
    "        NOTE: assumes each player has a fixed level\n",
    "        \n",
    "        Parameters:\n",
    "            params : np.array of alpha_ks, the freq of that level in population and lambda_ for QBR\n",
    "            dataset : list of plays, each play is an np array\n",
    "        Returns:\n",
    "            ll : loglikelihood of dataset\n",
    "\n",
    "        '''\n",
    "        alphas = params[0:-1]\n",
    "        lambda_ = params[-1] \n",
    "\n",
    "        ll = 0\n",
    "        for play in dataset: \n",
    "            for player in range(2):\n",
    "                sum = 0\n",
    "                for i, k in enumerate(range(self.K+1)): # condition on a specific value of k for a player\n",
    "                    alpha_k = alphas[i]\n",
    "                    traj = play[player]\n",
    "                    other_traj  = play[1-player] # trajectory of other player   \n",
    "                          \n",
    "                    pred_s = self.predict_traj(traj, other_traj, k, lambda_, alphas)\n",
    "                    prob = p_traj(traj, pred_s) # probability of that trajectory\n",
    "                    sum += alpha_k * (prob + 0.001) # this could be 0, so small epsilon added\n",
    "\n",
    "                assert sum != 0\n",
    "                ll += np.log(sum)\n",
    "\n",
    "        return -ll # since we are minimizing the negative log likelihood\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        params = np.zeros(self.K+2) # +2 since level 0 and the lambda parameter\n",
    "        params[0] = 1 # inital guess is that all players are level 0\n",
    "        params[-1] = 5 # intial guess for lambda\n",
    "\n",
    "        const_arr = np.ones(self.K+2)\n",
    "        const_arr[-1] = 0\n",
    "        #print(const_arr)\n",
    "        constraint = LinearConstraint(const_arr, lb=1, ub=1)\n",
    "        bnds = [(0, 1) for x in range(self.K+1)]\n",
    "        bnds.append((0, 1000)) # no bounds for lambda\n",
    "  \n",
    "        result = minimize(\n",
    "            self.log_likelihood ,\n",
    "            params, \n",
    "            args=(dataset),\n",
    "            bounds=bnds, \n",
    "            constraints=constraint) \n",
    "        print(result)\n",
    "\n",
    "        assert result.status == 0 # make sure the optimization was successful\n",
    "        self.alphas = result.x[0:-1]\n",
    "        self.lambda_ = result.x[-1]\n",
    "        #ll = result.fun\n",
    "        #return ll, self.alphas\n",
    "\n",
    "\n",
    "    def predict_traj(self, traj, other_traj, K, lambda_, alphas):\n",
    "        '''\n",
    "        Returns straetgy predictions against other player\n",
    "        \n",
    "        '''\n",
    "        L = other_traj.shape[1]\n",
    "        pred_i = np.zeros((2, self.K+1, L)) # level-k prediction for each stage game for i\n",
    "        pred_other = np.zeros((2, self.K+1, L)) # level-k prediction for each stage game for other player\n",
    "\n",
    "        for l in range(L):\n",
    "            # first determine level 0 strategy \n",
    "            start_hist_idx = max(l-self.h, 0)\n",
    "            end_hist_idx = l\n",
    "\n",
    "            if l == 0: # there is no history, so level-0 strategies are uniform\n",
    "                lvl_0_s_i = np.ones((2)) / 2\n",
    "                lvl_0_s_other = np.ones((2)) / 2\n",
    "            else:\n",
    "                hist_i = traj[:, start_hist_idx:end_hist_idx] # limited history of i's actions\n",
    "                hist_other = other_traj[:, start_hist_idx:end_hist_idx] # limited history of -i's actions\n",
    "                \n",
    "                lvl_0_s_i = np.sum(hist_i, axis=1)/np.sum(hist_i) # average strategy of i in history\n",
    "                lvl_0_s_other = np.sum(hist_other, axis=1)/np.sum(hist_other) # average strategy of -i in history\n",
    "\n",
    "            # These become the level 0 strategies\n",
    "            pred_i[:, 0, l] = lvl_0_s_i\n",
    "            pred_other[:, 0, l] = lvl_0_s_other\n",
    "\n",
    "            # Now, for higher levels:\n",
    "            for k in range(1, K+1):\n",
    "                if np.sum(alphas[0:k]) != 0:\n",
    "                    s_other = np.matmul(pred_other[:, 0:k, l], alphas[0:k]) / np.sum(alphas[0:k])\n",
    "                    s_i = np.matmul(pred_i[:, 0:k, l], alphas[0:k]) / np.sum(alphas[0:k])\n",
    "                else:\n",
    "                    s_other = np.matmul(pred_other[:, 0:k, l], np.ones(k)/k) \n",
    "                    s_i = np.matmul(pred_i[:, 0:k, l], np.ones(k)/k) \n",
    "                    \n",
    "                pred_i[:, k, l] = self.compute_BR(s_other, lambda_)  \n",
    "                pred_other[:, k, l] = self.compute_BR(s_i, lambda_)\n",
    " \n",
    "\n",
    "        pred_i = np.squeeze(pred_i[:, K, :]) # only return the level K predictions\n",
    "        return pred_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = np.array([[0.3, 0.7], [0.5, 0.5], [0.9, 0.1]]).T\n",
    "w = [0.2, 0.3, 0.3]\n",
    "np.matmul(pi, w) / np.sum(w )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 106.50696840687966\n",
      "     jac: array([-27.99727345, -28.00016499, -28.00016499, -28.00016499,\n",
      "         5.0526247 ])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 82\n",
      "     nit: 13\n",
      "    njev: 13\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.69200713e-02, 2.81243047e-08, 5.69888277e-01, 3.73191623e-01,\n",
      "       0.00000000e+00])\n"
     ]
    }
   ],
   "source": [
    "m = CH_Model(3, 2)\n",
    "\n",
    "t1 = data[0][0]\n",
    "t2 = data[0][1]\n",
    "\n",
    "r = m.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reason about future rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temporal_Model:\n",
    "    def __init__(self, h=1):\n",
    "        self.payoffs = np.zeros([2, 2, 2])\n",
    "        self.payoffs[0, :, :] = np.array([[0, -1],\n",
    "                                          [1, -2]])\n",
    "        self.payoffs[1, :, :] = np.array([[0, 1],\n",
    "                                         [-1, -2]])\n",
    "        self.alphas = None\n",
    "        self.h = h # the history length\n",
    "\n",
    "\n",
    "\n",
    "    def log_likelihood(self, params, dataset):\n",
    "        '''\n",
    "        Given the dataset and the fitted model, returns the log likelihood.\n",
    "\n",
    "        NOTE: assumes each player has a fixed level\n",
    "        \n",
    "        Parameters:\n",
    "            params : np.array of alpha_ks, the freq of that level in population and lambda_ for QBR\n",
    "            dataset : list of plays, each play is an np array\n",
    "        Returns:\n",
    "            ll : loglikelihood of dataset\n",
    "\n",
    "        '''\n",
    "        alphas = params[0:3] # frequency of different risk types in population\n",
    "        gammas = params[3:6] # parameter of risk types in population\n",
    "        lambda_ = params[-1] \n",
    "      \n",
    "\n",
    "        ll = 0\n",
    "        for play in dataset: \n",
    "            for player in range(2):\n",
    "                sum = 0\n",
    "                for i, alpha_gamma in enumerate(alphas): # condition on a specific type of  player\n",
    "                    traj = play[player]\n",
    "                    other_traj  = play[1-player] # trajectory of other player\n",
    "                    gamma = gammas[i]\n",
    "                    pred_s = self.predict_traj(traj, other_traj, lambda_, gamma)\n",
    "                    prob = p_traj(traj, pred_s) # probability of that trajectory\n",
    "                    sum += alpha_gamma * (prob) # this could be 0, so small epsilon added\n",
    "                ll += np.log(sum)\n",
    "\n",
    "        return -ll # since we are minimizing the negative log likelihood\n",
    "\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        params = np.zeros(7) # +2 since level 0 and the lambda parameter\n",
    "    \n",
    "        for i in range(3):\n",
    "            params[i] = 1/3\n",
    "\n",
    "        params[3] = 0.5\n",
    "        params[4] = 1\n",
    "        params[5] = 2\n",
    "        params[6] = 1 # intial guess for lambda\n",
    "\n",
    "        const_arr = np.zeros(7)\n",
    "        for i in range(3):\n",
    "            const_arr[i] = 1\n",
    "\n",
    "       \n",
    "        constraint = LinearConstraint(const_arr, lb=1, ub=1)\n",
    "        bnds = [(0, 1) for x in range(3)]\n",
    "       \n",
    "        bnds.append((-1000, 1))\n",
    "        bnds.append((1, 1))\n",
    "        bnds.append((1, 1000))\n",
    "        bnds.append((0, 1000)) # no bounds for lambda\n",
    "       \n",
    "        result = minimize(\n",
    "            self.log_likelihood ,\n",
    "            params, \n",
    "            args=(dataset),\n",
    "            bounds=bnds, \n",
    "            constraints=constraint) \n",
    "        print(result)\n",
    "\n",
    "        assert result.status == 0 # make sure the optimization was successful\n",
    "    \n",
    "    \n",
    "        \n",
    "    def predict_traj(self, traj, other_traj, lambda_, gamma): \n",
    "        '''\n",
    "        I think about what action I can take\n",
    "\n",
    "        what do I think you will play this round? \n",
    "        -> probably a best response to my last action\n",
    "\n",
    "        what do I think you will play next round?\n",
    "        -> probably a brest resonse to this aciton\n",
    "\n",
    "        what will I play next round? \n",
    "            -> probably a best resonse to what I think you will play next round\n",
    "        '''\n",
    "        L = other_traj.shape[1]\n",
    "        pred_i = np.zeros((2, L)) # level-k prediction for each stage game for i\n",
    "\n",
    "        for l in range(L):\n",
    "            if l == 0:\n",
    "                # if action 0\n",
    "                s_other_next = self.BR(np.array([1,0]), lambda_)\n",
    "                s_i_next = self.BR(s_other_next, lambda_)\n",
    "                eu_0 = expected_utility([np.array([1,0]), np.array([0.5, 0.5])], self.payoffs[0]) + gamma*expected_utility([s_i_next, s_other_next], self.payoffs[0])\n",
    "\n",
    "                # if action 1\n",
    "                s_other_next = self.BR(np.array([0,1]), lambda_)\n",
    "                s_i_next = self.BR(s_other_next, lambda_)\n",
    "                eu_1 =  expected_utility([np.array([0,1]), np.array([0.5, 0.5])], self.payoffs[0]) + gamma*expected_utility([s_i_next, s_other_next], self.payoffs[0])\n",
    "           \n",
    "            else:\n",
    "                # if action 0\n",
    "                s_other_curr = self.BR(traj[:, l-1], lambda_)\n",
    "                #print('What I think the opponent will play this round')\n",
    "                #print( s_other_curr)\n",
    "                s_other_next = self.BR(np.array([1,0]), lambda_)\n",
    "               # print('What I think the opponent will play next round')\n",
    "               # print(s_other_next)\n",
    "                s_i_next = self.BR(s_other_next, lambda_)\n",
    "               # print('What I will play next round')\n",
    "               # print(s_i_next)\n",
    "                eu_0 = expected_utility([np.array([1,0]), s_other_curr], self.payoffs[0]) + gamma*expected_utility([s_i_next, s_other_next], self.payoffs[0])\n",
    "\n",
    "                # if action 1\n",
    "                s_other_curr = self.BR(traj[:, l-1], lambda_)\n",
    "                s_other_next = self.BR(np.array([0,1]), lambda_)\n",
    "                s_i_next = self.BR(s_other_next, lambda_)\n",
    "                eu_1 = expected_utility([np.array([0,1]), s_other_curr], self.payoffs[0]) + gamma*expected_utility([s_i_next, s_other_next], self.payoffs[0])\n",
    "\n",
    "\n",
    "                #print(eu_0)\n",
    "              #  print(eu_1)\n",
    "            pred_i[:, l]  = softmax(lambda_* np.array([eu_0, eu_1]))\n",
    "\n",
    "        return pred_i   \n",
    "\n",
    "\n",
    "    def BR(self,  s_other, lambda_):\n",
    "        '''\n",
    "        Computes a best response\n",
    "\n",
    "        Parameters:\n",
    "            s_other : (np.Array) strategy profile of other player\n",
    "\n",
    "        NOTE: this ONLY works with symetric payoffs and 2 actions\n",
    "        '''\n",
    "    \n",
    "        #get EU of action 0\n",
    "    \n",
    "        s = [np.array([1, 0]), s_other]\n",
    "        eu_0 = expected_utility(s, self.payoffs[0])\n",
    "\n",
    "        # get EU of action 1\n",
    "        s = [np.array([0, 1]), s_other]\n",
    "        eu_1 = expected_utility(s, self.payoffs[0])\n",
    "\n",
    "\n",
    "        # if eu_0 >= eu_1:\n",
    "        #     return np.array([1,0])\n",
    "        # else:\n",
    "        #     return np.array([0,1])\n",
    "\n",
    "        # return action with greater EU\n",
    "        return softmax(np.array([eu_0, eu_1])*lambda_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 114.69670141201314\n",
      "     jac: array([-2.80003872e+01, -2.75060768e+01, -2.79992981e+01, -3.11851501e-04,\n",
      "                   nan,  6.11305237e-04,  5.21087646e-03])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 155\n",
      "     nit: 21\n",
      "    njev: 21\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 6.42297455e-01,  5.88386355e-16,  3.57702545e-01, -2.08624873e+00,\n",
      "        1.00000000e+00,  2.32798801e+00,  5.71300232e-01])\n"
     ]
    }
   ],
   "source": [
    "m = Temporal_Model()\n",
    "\n",
    "t1 = data[0][0]\n",
    "t2 = data[0][1]\n",
    "\n",
    "\n",
    "# print(t1)\n",
    "# print(m.predict_traj(t1, t2, 2, 1000 ))\n",
    "# print(t2)\n",
    "# # m.predict_traj(t1, t2, 2, 5, overall=True, alphas=[0, 1, 0])\n",
    "\n",
    "#   alphas = params[0:3] # frequency of different risk types in population\n",
    "#   gammas = params[3:6] # parameter of risk types in population\n",
    "#   lambda_ = params[-1] \n",
    "\n",
    "# print(m.predict_traj(t2, t1, 2, 1000))\n",
    "r = m.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reason about future and I have a level of reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temporal_Level_Model:\n",
    "    def __init__(self, h=1):\n",
    "        self.payoffs = np.zeros([2, 2, 2])\n",
    "        self.payoffs[0, :, :] = np.array([[0, -1],\n",
    "                                          [1, -2]])\n",
    "        self.payoffs[1, :, :] = np.array([[0, 1],\n",
    "                                         [-1, -2]])\n",
    "        self.alphas = None\n",
    "        self.h = h # the history length\n",
    "\n",
    "\n",
    "\n",
    "    def log_likelihood(self, params, dataset):\n",
    "        '''\n",
    "        Given the dataset and the fitted model, returns the log likelihood.\n",
    "\n",
    "        NOTE: assumes each player has a fixed level\n",
    "        \n",
    "        Parameters:\n",
    "            params : np.array of alpha_ks, the freq of that level in population and lambda_ for QBR\n",
    "            dataset : list of plays, each play is an np array\n",
    "        Returns:\n",
    "            ll : loglikelihood of dataset\n",
    "\n",
    "        '''\n",
    "        alpha_ks = params[0:3] #\n",
    "        gamma = params[3] # parameter of risk types in population\n",
    "        lambda_ = params[4] \n",
    "        kappa = params[5]\n",
    "      \n",
    "\n",
    "        ll = 0\n",
    "        for play in dataset: \n",
    "            for player in range(2):\n",
    "                sum = 0\n",
    "                for k, alpha_k in enumerate(alpha_ks):\n",
    "                    traj = play[player]\n",
    "                    other_traj  = play[1-player] # trajectory of other player\n",
    "                    pred_s = self.predict_traj(traj, other_traj, lambda_, gamma, k, kappa)\n",
    "                    prob = p_traj(traj, pred_s) # probability of that trajectory\n",
    "                    sum += alpha_k * (prob) # this could be 0, so small epsilon added\n",
    "            \n",
    "                ll += np.log(sum)\n",
    "\n",
    "        return -ll # since we are minimizing the negative log likelihood\n",
    "\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        params = np.zeros(6) # +2 since level 0 and the lambda parameter\n",
    "    \n",
    "\n",
    "        for i in range(3):\n",
    "            params[i] = 1/3\n",
    "\n",
    "        params[3] = 1 # gamma \n",
    "        params[4] = 1 # lambda\n",
    "        params[4] = 0.5 # kappa\n",
    "\n",
    "        const_arr = np.zeros(6)\n",
    "        \n",
    "        for i in range(3):\n",
    "            const_arr[i] = 1\n",
    "        constraint = LinearConstraint(const_arr, lb=1, ub=1)\n",
    "\n",
    "        bnds = [(0, 1) for x in range(3)]\n",
    "\n",
    "        bnds.append((0, 100))\n",
    "        bnds.append((0, 100))\n",
    "        bnds.append((0, 1))\n",
    "       \n",
    "        result = minimize(\n",
    "            self.log_likelihood ,\n",
    "            params, \n",
    "            args=(dataset),\n",
    "            bounds=bnds, \n",
    "            constraints=constraint) \n",
    "        print(result)\n",
    "\n",
    "        assert result.status == 0 # make sure the optimization was successful\n",
    "    \n",
    "    \n",
    "        \n",
    "    def predict_traj(self, traj, other_traj, lambda_, gamma, k, kappa): \n",
    "        '''\n",
    "        I think about what action I can take\n",
    "\n",
    "        what do I think you will play this round? \n",
    "        -> probably a best response to my last action\n",
    "\n",
    "        what do I think you will play next round?\n",
    "        -> probably a brest resonse to this aciton\n",
    "\n",
    "        what will I play next round? \n",
    "            -> probably a best resonse to what I think you will play next round\n",
    "        '''\n",
    "        def level_k_strat(lvl_0_p0, lvl_0_p1, k):\n",
    "            nonlocal lambda_\n",
    "            if k == 0:\n",
    "                return [lvl_0_p0, lvl_0_p1]\n",
    "\n",
    "            lvl_kminus1_p0 = lvl_0_p0\n",
    "            lvl_kminus1_p1 = lvl_0_p1\n",
    "\n",
    "            for k in range(1, k+1):\n",
    "                lvl_k_p0 = self.compute_BR(lvl_kminus1_p1, lambda_)\n",
    "                lvl_k_p1 = self.compute_BR(lvl_kminus1_p0, lambda_)\n",
    "                lvl_kminus1_p0 = lvl_k_p0\n",
    "                lvl_kminus1_p1 = lvl_k_p1\n",
    "\n",
    "            return [lvl_k_p0, lvl_k_p1]\n",
    "\n",
    "\n",
    "        def get_weights(h, kappa):\n",
    "            if h == 1:\n",
    "                return np.ones(1)\n",
    "            \n",
    "            l = [1-kappa]\n",
    "            for i in range(1, h-1):\n",
    "                l.append(l[i-1]*kappa)\n",
    "\n",
    "            l.append(1- np.sum(l))\n",
    "            assert np.sum(l) == 1\n",
    "            return np.array(l)\n",
    "\n",
    "\n",
    "\n",
    "        L = other_traj.shape[1]\n",
    "        pred_i = np.zeros((2, L)) # level-k prediction for each stage game for i\n",
    "\n",
    "        for l in range(L):\n",
    "           \n",
    "            if l == 0:\n",
    "                pred_i[:, l] = np.array([0.5, 0.5])\n",
    "\n",
    "            else:\n",
    "                if k == 0:\n",
    "                    pred_i[:, l] = np.array([0.5, 0.5])\n",
    "\n",
    "                elif k == 1:\n",
    "                    start_hist_idx = max(l-self.h, 0)\n",
    "                    end_hist_idx = l\n",
    "                 \n",
    "                    hist_other = other_traj[:, start_hist_idx:end_hist_idx] # limited history of -i's actions\n",
    "                    \n",
    "                    w = get_weights(hist_other.shape[1], kappa)\n",
    "\n",
    "                    lvl_0_s_other = np.dot(hist_other, w)\n",
    "                    pred_i[:, l] = self.BR(lvl_0_s_other, lambda_)\n",
    "\n",
    "                else:\n",
    "                    start_hist_idx = max(l-self.h, 0)\n",
    "                    end_hist_idx = l\n",
    "                  \n",
    "                    hist_i = traj[:, start_hist_idx:end_hist_idx] # limited history of i's actions\n",
    "                    hist_other = other_traj[:, start_hist_idx:end_hist_idx] # limited history of -i's actions\n",
    "                    \n",
    "\n",
    "                    def eu(action, hist_i, hist_other):\n",
    "                        nonlocal gamma,l\n",
    "\n",
    "                        w = get_weights(hist_other.shape[1], kappa)\n",
    "                        lvl_0_s_i = np.dot(hist_i, w)\n",
    "                        lvl_0_s_other = np.dot(hist_other, w)\n",
    "\n",
    "                        #lvl_0_s_i = np.sum(hist_i, axis=1)/np.sum(hist_i) # average strategy of i in history\n",
    "                        #lvl_0_s_other = np.sum(hist_other, axis=1)/np.sum(hist_other) # average strategy of -i in history\n",
    "\n",
    "                        # aciton 0:\n",
    "                        hist_i_new = np.c_[hist_i, action] # limited history of i's actions\n",
    "                        if hist_i_new.shape[0] > self.h:\n",
    "                            hist_i_new = np.delete(hist_i_new, 0, axis=1)\n",
    "\n",
    "                        w = get_weights(hist_i_new.shape[1], kappa)\n",
    "                        lvl_0_s_i_new = np.dot(hist_i_new,  w) # average strategy of i in history\n",
    "                    \n",
    "                        eu = expected_utility(action, self.BR(lvl_0_s_i, lambda_)) + gamma*expected_utility( lvl_0_s_i_new , self.BR(lvl_0_s_i_new, lambda_))\n",
    "                        return eu\n",
    "\n",
    "                    eu_0 = eu(np.array([1,0]), hist_i, hist_other)\n",
    "                    eu_1 = eu(np.array([0,1]), hist_i, hist_other)\n",
    "                    pred_i[:, l] = softmax(np.array([eu_0, eu_1])*lambda_)\n",
    "\n",
    "        return pred_i\n",
    "        \n",
    "    def BR(self,  s_other, lambda_):\n",
    "        '''\n",
    "        Computes a best response\n",
    "\n",
    "        Parameters:\n",
    "            s_other : (np.Array) strategy profile of other player\n",
    "\n",
    "        NOTE: this ONLY works with symetric payoffs and 2 actions\n",
    "        '''\n",
    "    \n",
    "        #get EU of action 0\n",
    "    \n",
    "        s = [np.array([1, 0]), s_other]\n",
    "        eu_0 = expected_utility(s, self.payoffs[0])\n",
    "\n",
    "        # get EU of action 1\n",
    "        s = [np.array([0, 1]), s_other]\n",
    "        eu_1 = expected_utility(s, self.payoffs[0])\n",
    "\n",
    "\n",
    "        # if eu_0 >= eu_1:\n",
    "        #     return np.array([1,0])\n",
    "        # else:\n",
    "        #     return np.array([0,1])\n",
    "\n",
    "        # return action with greater EU\n",
    "        return softmax(np.array([eu_0, eu_1])*lambda_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(h, kappa):\n",
    "    if h == 1:\n",
    "        return np.ones(1)\n",
    "    \n",
    "    l = [1-kappa]\n",
    "    \n",
    "    for i in range(1, h-1):\n",
    "        l.append(l[i-1]*kappa)\n",
    "\n",
    "    l.append(1- np.sum(l))\n",
    "    assert np.sum(l) == 1\n",
    "    return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7  , 0.21 , 0.063, 0.027])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weights(4, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 119.2213150563104\n",
      "     jac: array([-28.0000001, -28.       , -28.       ,   0.       ,   0.       ,\n",
      "         0.       ])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 14\n",
      "     nit: 2\n",
      "    njev: 2\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.5, 0. , 0.5, 1. , 0. , 0. ])\n"
     ]
    }
   ],
   "source": [
    "m = Temporal_Level_Model(h = 2)\n",
    "m.fit(data)\n",
    "t1 = data[0][0]\n",
    "t2 = data[0][1]\n",
    "\n",
    "\n",
    "# print(t1)\n",
    "#print(m.predict_traj(t1, t2, lambda_=1, gamma=1, k=1))\n",
    "# print(t2)\n",
    "# # m.predict_traj(t1, t2, 2, 5, overall=True, alphas=[0, 1, 0])\n",
    "\n",
    "#m.log_likelihood( [1, 0, 0, 1, 1, 0.25], data)\n",
    "# print(m.predict_traj(t2, t1, 2, 1000))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "174d5a967417a2ba15b92fee30b6658756f13acfa6c5a4bc13885d05104c7799"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('bgt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
